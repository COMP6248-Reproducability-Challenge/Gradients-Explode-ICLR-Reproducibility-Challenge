\documentclass{article} % For LaTeX2e
\usepackage{iclr2019_conference,times}

\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}
\pagestyle{plain}

\title{Reproducibility Report}

\author{Hamish Flynn\\
ID: 30635462\\
\texttt{hef1g18@soton.ac.uk}\\
\And
Richard\\
ID: some number\\
\texttt{thing@soton.ac.uk}\\
\And
Aaron\\
ID: some number\\
\texttt{thing@soton.ac.uk}}

\iclrfinalcopy

\begin{document}

\maketitle

\begin{abstract}
We have attempted to reproduce the main results of George Philipp's paper "Gradients Explode - Deep Networks Are Shallow - ResNets Explained" which was invited to the workshop track at ICLR 2018. The authors attempt to show that techniques such as Adam, batch normalisation and SeLU nonlinearities do not solve the exploding gradient problem that MLPs can suffer from. Then the authors propose an explanation for why exploding gradients occur and highlight the collapsing domain problem.
\end{abstract}

\section{Introduction}

Come and see our GitHub :]]\\
\texttt{https://github.com/JeremyLinux/ICLR-Reproducability-Challenge}

\vspace{5mm}

\section{Notation}



\vspace{5mm}

\section{Experiments}



\vspace{5mm}

\subsection{Gradients Explode - Despite Bounded Activation Functions}

\subsubsection{What did they do?/Why?}



\subsubsection{Results From Paper}



\subsubsection{Reproduced Results}



\vspace{5mm}

\subsection{Exploding Gradients Limit Depth - The Residual Trick}

\subsubsection{What did they do?/Why?}



\subsubsection{Results From Paper}



\subsubsection{Reproduced Results}



\vspace{5mm}

\subsection{ResNet Reduces The Gradient - And ResNet Explained}

\subsubsection{What did they do?/Why?}



\subsubsection{Results From Paper}



\subsubsection{Reproduced Results}



\vspace{5mm}

\section{Reflection}

Did we get the same results?\\
How difficult was it to reproduce the results?

\vspace{5mm}

\section{Conclusion}



\vspace{5mm}

\end{document}